{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据准备\n",
    "本例训练集、测试集均从train.csv中取，各10k。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def read_ad_click_data(n, offset=0): # offset是偏移量，即从第几行开始读\n",
    "    X_dict, y =[],[]\n",
    "    with open('train.csv','r') as csvfile: # 本例训练集、测试集均从train.csv中取\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        # 跳过前offset行\n",
    "        for i in range(offset): # 若offset=0,该语句不做任何处理\n",
    "            next(reader)\n",
    "        # 逐行读取数据，删除每行的几个字段，即删除这几列特征\n",
    "        i = 0\n",
    "        for row in reader:\n",
    "            i += 1\n",
    "            y.append(int(row['click']))\n",
    "            del row['click'],row['id'],row['hour'],row['device_id'],row['device_ip'] \n",
    "            X_dict.append(dict(row))\n",
    "            if i >=n:\n",
    "                break\n",
    "    return X_dict,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n = 10000\n",
    "X_dict_train, y_train = read_ad_click_data(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_dict_train)\n",
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C1': '1005',\n",
       " 'C14': '15706',\n",
       " 'C15': '320',\n",
       " 'C16': '50',\n",
       " 'C17': '1722',\n",
       " 'C18': '0',\n",
       " 'C19': '35',\n",
       " 'C20': '-1',\n",
       " 'C21': '79',\n",
       " 'app_category': '07d7df22',\n",
       " 'app_domain': '7801e8d9',\n",
       " 'app_id': 'ecad2386',\n",
       " 'banner_pos': '0',\n",
       " 'device_conn_type': '2',\n",
       " 'device_model': '44956a24',\n",
       " 'device_type': '1',\n",
       " 'site_category': '28905ebd',\n",
       " 'site_domain': 'f3845767',\n",
       " 'site_id': '1fbe01fe'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dict_train[0]\n",
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot Encoding 一位有效编码\n",
    "将字典里的（特征：特征值）转换为向量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas.get_dummies()  将string 转换为integers\n",
    "\n",
    "- Sklearn.preprocessing.OneHotEncoder()  不可以直接处理string，需要先转换为integers\n",
    "\n",
    "- Sklearn.feature_extraction.DictVectorizer 将字典类型 转换为向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2820\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "dict_one_hot_encoder = DictVectorizer(sparse=False)\n",
    "X_train = dict_one_hot_encoder.fit_transform(X_dict_train)\n",
    "print(len(X_train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们将原来的19维 转换成了 2820维binary特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 同上，构造测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_dict_test,y_test = read_ad_click_data(n,n) # 取10k行，跳过前10k行\n",
    "\n",
    "X_test = dict_one_hot_encoder.transform(X_dict_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2820"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test[0])\n",
    "len(X_dict_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练\n",
    "接下来我们采用grid search 技巧训练一个决策树模型。此处做示范，仅对max_depth调优。\n",
    "\n",
    "**注意，分类的度量应该用AUC of ROC，因为数据是失衡的，只有1706/10000的样本是click**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 8294, 1: 1706})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "parameters = {'max_depth': [3,10,None]}\n",
    "decision_tree = DecisionTreeClassifier(criterion='gini',min_samples_split=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_search = GridSearchCV(decision_tree,parameters, n_jobs=-1, cv=3, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best'),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'max_depth': [3, 10, None]}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score=True, scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 26.025s seconds ---\n",
      "{'max_depth': 10}\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "start_time = timeit.default_timer()\n",
    "grid_search.fit(X_train,y_train)\n",
    "print('--- %0.3fs seconds ---' % (timeit.default_timer()-start_time))\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用最优模型预测测试集："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decision_tree_best = grid_search.best_estimator_\n",
    "pos_prob = decision_tree_best.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ROC AUC on testing set is: 0.671\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score # input是y_test 和概率值\n",
    "print('The ROC AUC on testing set is: {0:.3f}'.format(roc_auc_score(y_test, pos_prob)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUC 为0.671，似乎并不是很好。但广告点击行为涉及很多人为因素，其预测本身就很困难。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回顾以下，决策树是在训练集上，通过贪婪算法找每一步的最佳分裂点。但这容易导致过拟合，因为这些最佳点可能只限于训练集中最佳。庆幸的是，随机森林可以纠正这个缺陷，并给出性能更优的树模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 随机森林\n",
    "集成，bagging (bootstrap aggregating)，能很有效地**克服过拟合**。\n",
    "\n",
    "n个训练集，每个训练集训练出一个独立的分类模型，这些模型‘投票’决出最终的判定。其中每个训练集里的样本，由原始数据集，有放回地随机抽取。\n",
    "\n",
    "Tree Bagging 能降低决策树模型的高方差问题，所以常优于单棵树。\n",
    "\n",
    "然而，在某些情况下，其一个或多个特征是强有力的指标，单个树主要是根据这些特征构造的，因而变得高度相关。聚合多个相关树不会有多大差别。为了使每棵树变得不相关，在每个节点寻找最佳分裂点时，随机取几个特征作子集来考虑。现在，**每个训练集的features也不一致**，各树据此训练，保证了更多的多样性和更好的性能。随机森林是，features也bagging（随机获得）的另类tree bagging 模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=100, n_jobs=-1, oob_score=False,\n",
       "            random_state=None, verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'max_depth': [3, 10, None]}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score=True, scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': None}\n"
     ]
    }
   ],
   "source": [
    "# 同样只对max_depth调参\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators=100,criterion='gini',min_samples_split=30,\n",
    "                                      n_jobs=-1)\n",
    "grid_search = GridSearchCV(random_forest, parameters,n_jobs=-1,cv=3,scoring='roc_auc')\n",
    "\n",
    "grid_search.fit(X_train,y_train)\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC of ROC is: 0.714\n"
     ]
    }
   ],
   "source": [
    "random_forest_best = grid_search.best_estimator_\n",
    "pos_prob = random_forest_best.predict_proba(X_test)[:,1]\n",
    "print('The AUC of ROC is: {0:.3f}'.format(roc_auc_score(y_test,pos_prob)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "性能有所提升"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "另有3个重要参数也值得调优，也能提高模型性能：\n",
    "\n",
    "* max_features: 每次寻找最佳分裂点使考虑的特征数。\n",
    "    \n",
    "    1. 惯用的，对于m维的数据集，便取 √m，通过max_features='sqrt'执行；\n",
    "    2. 其他选项还有'log2'；\n",
    "    3. 原始特征数的20%-50%。 \n",
    "    \n",
    "    \n",
    "* n_estimators: \n",
    "    \n",
    "    集成几颗树。一般来说，树越多越好，但计算量也会增大。通常设为100、200、500等\n",
    "\n",
    "\n",
    "* min_samples_split: \n",
    "\n",
    "    在一个节点进一步分裂所需的最小样本数。若取值太小，容易过拟合；太大，则欠拟合。10、30、50。\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
