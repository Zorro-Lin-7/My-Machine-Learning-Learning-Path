{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from nltk.corpus import names\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_names = set(names.words())\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def letter_only(astr):\n",
    "    for c in astr:\n",
    "        if not c.isalpha():\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def clean_text(docs):\n",
    "    cleaned_docs = []\n",
    "    for doc in docs:\n",
    "        cleaned_docs.append(' '.join([lemmatizer.lemmatize(word.lower()) for word in doc.split()\n",
    "                                      if letter_only(word) and word not in all_names]))\n",
    "    return cleaned_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据准备，本例采用2个类别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "categories = ['comp.graphics', 'sci.space']\n",
    "\n",
    "data_train = fetch_20newsgroups(subset='train',categories=categories, random_state=42)\n",
    "data_test = fetch_20newsgroups(subset='test', categories=categories, random_state=42)\n",
    "\n",
    "cleaned_train = clean_text(data_train.data)\n",
    "label_train = data_train.target\n",
    "cleaned_test = clean_text(data_test.data)\n",
    "label_test = data_test.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1177"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "783"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_train)\n",
    "len(label_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 一个好的经验：确定类别是否失衡："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 584, 1: 593})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Counter({0: 389, 1: 394})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(label_train)\n",
    "Counter(label_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 提取tf-idf特征："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cleaned_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-b24974488bd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m tfidf_vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5, stop_words='english',\n\u001b[1;32m      2\u001b[0m                                    max_features = 8000)\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mterm_docs_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfidf_vectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleaned_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mterm_docs_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfidf_vectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleaned_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cleaned_train' is not defined"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5, stop_words='english',\n",
    "                                   max_features = 8000)\n",
    "term_docs_train = tfidf_vectorizer.fit_transform(cleaned_train)\n",
    "term_docs_test = tfidf_vectorizer.transform(cleaned_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 应用SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC(kernel='linear', C=1.0, random_state=42) # 核函数选择线性，惩罚系数默认C=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=42, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.fit(term_docs_train, label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy on testing set is: 96.4%\n"
     ]
    }
   ],
   "source": [
    "# 模型训练后，输入(X,y)可直接得到accuracy，score方法内含预测过程\n",
    "accuracy = svm.score(term_docs_test, label_test) \n",
    "print('The accuracy on testing set is: {0:.1f}%'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多类别分类\n",
    "2中方法：\n",
    "### one-vs-all![one-vs-all](one-vs-all.png)\n",
    "对于新样本x'，代入每个classifer **w**x'+b，值越大，越可能为\"正\"。\n",
    "例如，\n",
    "\n",
    "**w_r** x'+ b = - 0.78\n",
    "\n",
    "**w_b** x' + b = - 0.35\n",
    "\n",
    "**w_g** x' + b = - 0.642\n",
    "\n",
    "那么x'属于blue class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### one-vs-one![one-vs-one](one-vs-one.png)\n",
    "\n",
    "所有类两两组合，每次与一对进行训练，得到相应的classifier。新样本x'代入各分类器，各分类器的结果进行“投票”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "就准确率而言，两种策略效果差不多。就计算量而言，one-vs-one的计算代价更小。sklearn中，采用的是one-vs-one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=42, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy on testing set is: 88.6%\n"
     ]
    }
   ],
   "source": [
    "categories = [\n",
    "    'alt.atheism',\n",
    "    'talk.religion.misc',\n",
    "    'comp.graphics',\n",
    "    'sci.space',\n",
    "    'rec.sport.hockey'\n",
    "]\n",
    "data_train = fetch_20newsgroups(subset='train', categories=categories, random_state=42)\n",
    "data_test = fetch_20newsgroups(subset='test', categories=categories, random_state=42)\n",
    "\n",
    "cleaned_train = clean_text(data_train.data)\n",
    "label_train = data_train.target\n",
    "cleaned_test = clean_text(data_test.data)\n",
    "label_test = data_test.target\n",
    "\n",
    "term_docs_train = tfidf_vectorizer.fit_transform(cleaned_train)\n",
    "term_docs_test = tfidf_vectorizer.transform(cleaned_test)\n",
    "\n",
    "svm = SVC(kernel='linear', C=1.0, random_state=42)\n",
    "svm.fit(term_docs_train, label_train)\n",
    "accuracy = svm.score(term_docs_test, label_test)\n",
    "print('The accuracy on testing set is: {0:.1f}%'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.77      0.79       319\n",
      "          1       0.91      0.94      0.93       389\n",
      "          2       0.98      0.96      0.97       399\n",
      "          3       0.93      0.93      0.93       394\n",
      "          4       0.73      0.76      0.74       251\n",
      "\n",
      "avg / total       0.89      0.89      0.89      1752\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "prediction = svm.predict(term_docs_test)\n",
    "report = classification_report(label_test, prediction)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "参数C控制间隔的严格程度即偏差与方差的制衡：\n",
    "    \n",
    "    C越大，越严格，间隔越小，偏差越小，方差越大；\n",
    "    C越小，越宽松，间隔越打，偏差越大，方差越小。\n",
    "    \n",
    "![C](C.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 非线性可分问题——Kernels\n",
    "低维映射到高维空间"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最常用的kernel是RBF，也就是Gaussion kernel![Gaussion](RBF.png)\n",
    "其中𝛾是kernel coefficient，决定核函数fit观测样本的特异程度或者泛化程度。\n",
    "\n",
    "![gamma](gamma.png)\n",
    "\n",
    "𝛾值很大（注意前面的负号），表示方差很小，相对准确地fit训练样本，这可能导致高偏差；\n",
    "\n",
    "𝛾值小，则表示高方差，广泛的fit，这可能导致过拟合。\n",
    "\n",
    "𝛾的最佳选择通过交叉验证得到"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 线性核与RBF核的选择"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "经验上，文本数据都是线性可分的，用线性核。\n",
    "\n",
    "以下三种情形，线性核优于高斯核：\n",
    "\n",
    "    Case 1: 实例数和特征数都很大，超过104或105。因为特征空间的维度足够大，RBF转换而来的额外特征将不会提供任何性能改进，却会增加计算代价。\n",
    "    Case 2: 特征数远大于训练样本数。除了case 1的原因，RBF核对过拟合有显著倾向。\n",
    "    Case 3: 实例数显著大于特征数。对于低维的数据集，RBF会以“映射到高维空间”来提升性能，但由于训练的复杂度，它通常对样本数超过106或107的训练集不再有效。\n",
    "    \n",
    "除此之外，高斯核是第一选择。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## News topic classification with SVM\n",
    "最后建立一个最完整的SVM 新闻主题分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "categories = None\n",
    "data_train = fetch_20newsgroups(subset='train', categories=categories,random_state=42)\n",
    "data_test = fetch_20newsgroups(subset='test', categories=categories, random_state=42)\n",
    "\n",
    "cleaned_train = clean_text(data_train.data)\n",
    "label_train = data_train.target\n",
    "\n",
    "cleaned_test = clean_text(data_test.data)\n",
    "label_test = data_test.target\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5, stop_words='english',\n",
    "                                   max_features = 8000)\n",
    "term_docs_train = tfidf_vectorizer.fit_transform(cleaned_train)\n",
    "term_docs_test = tfidf_vectorizer.transform(cleaned_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#经验上，文本分类用线性核；惩罚系数C通过交叉验证选择：\n",
    "from sklearn.svm import SVC\n",
    "svc_libsvm = SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV\n",
    "之前的交叉验证都是手动地拆成几折，然后用for循环验证每个参数。接下来用一个更优雅的GridSearchCV，它的整个过程包含了拆分数据集、folds generation、交叉训练和验证、找出最佳参数组合。\n",
    "\n",
    "我们只需指定参数和参数值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = {'C': (0.1, 1, 10, 100)}\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_search = GridSearchCV(svc_libsvm, parameters, n_jobs=-1, cv=3)\n",
    "# 初始化为：3折cv，并行跑空余的CPU核（n_job=-1）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'C': (0.1, 1, 10, 100)}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 353.210s seconds ---\n"
     ]
    }
   ],
   "source": [
    "import timeit #记录调参数用时：\n",
    "start_time = timeit.default_timer()\n",
    "grid_search.fit(term_docs_train, label_train)\n",
    "print('--- %0.3fs seconds ---' % (timeit.default_timer() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 得到最佳参数\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8665370337634789"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 最佳参数下，3折平均性能\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 得出最佳参数后，就可代入SVM模型，用于未知的testing set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy on testing set is: 76.2%\n"
     ]
    }
   ],
   "source": [
    "svc_libsvm_best = grid_search.best_estimator_\n",
    "accuracy = svc_libsvm_best.score(term_docs_test, label_test)\n",
    "print('The accuracy on testing set is: {0:.1f}%'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要注意的是，模型调优是基于已经“打过折”的原始训练集，即内含验证集。\n",
    "\n",
    "而我们采用的最佳模型是基于原始testing set，以确保对全新数据集的泛化能力。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于SVM 基本型的求解，它是二次规划问题，sklearn 的svm 基于libsvm 和liblinear 两个开源库。\n",
    "上面的 76.2% 是基于libsvm 的 SVC model，\n",
    "\n",
    "#### 接下来试试另一个： LinearSVC，它同样是用线性核，但基于liblinear实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'C': (0.1, 1, 10, 100)}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 14.563s seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC \n",
    "svc_linear = LinearSVC()\n",
    "grid_search = GridSearchCV(svc_linear, parameters, n_jobs=-1, cv=3)\n",
    "start_time = timeit.default_timer()\n",
    "grid_search.fit(term_docs_train,label_train)\n",
    "print('--- %0.3fs seconds' % (timeit.default_timer()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8707795651405339"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy on testing set is : 77.88%\n"
     ]
    }
   ],
   "source": [
    "svc_linear_best = grid_search.best_estimator_\n",
    "accuracy = svc_linear_best.score(term_docs_test,label_test)\n",
    "print('The accuracy on testing set is : {0:.2f}%'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "准确率稍高，速度快了10倍以上。因为liblinear 库是为大数据集设计的，而libsvm对于超过二次的计算复杂度，训练样本数超过105就无法很好地规模计算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 调优feature extractor——TfidfVectorizer model，进一步提升性能\n",
    "feature extraction和 classification 作为2个连续步骤，应该同时进行交叉验证。我们利用**pipeline**实现："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words='english')), # tfidf feature extractor\n",
    "    ('svc', LinearSVC()),                            # linear SVM classifier\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同时进行“两步”的参数调优，形式如下：中间用\"__\"连接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters_pipeline = {\n",
    "    'tfidf__max_df': (0.25, 0.5),  # 一个词的最大文档频数，防止常见词频繁出现在文档中\n",
    "    'tfidf__max_features': (40000, 50000), \n",
    "    'tfidf__sublinear_tf': (True, False), # 是否用log函数缩放词频\n",
    "    'tfidf__smooth_idf': (True, False), # 文档频数是否加1，防止除零错误\n",
    "    'svc__C': (0.1, 1, 10, 100),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       " ...ax_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0))]),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'tfidf__max_df': (0.25, 0.5), 'tfidf__max_features': (40000, 50000), 'tfidf__sublinear_tf': (True, False), 'tfidf__smooth_idf': (True, False), 'svc__C': (0.1, 1, 10, 100)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 653.694s secondes ---\n"
     ]
    }
   ],
   "source": [
    "grid_search = GridSearchCV(pipeline, parameters_pipeline, n_jobs=-1, cv=3)\n",
    "start_time = timeit.default_timer()\n",
    "grid_search.fit(cleaned_train, label_train) # 用的是未做特征提取的cleaned_train\n",
    "print('--- %0.3fs secondes ---' % (timeit.default_timer() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svc__C': 1, 'tfidf__max_df': 0.5, 'tfidf__max_features': 40000, 'tfidf__smooth_idf': False, 'tfidf__sublinear_tf': True}\n",
      "0.888368393141\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后应用与testing set："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy on testing set is: 80.6%\n"
     ]
    }
   ],
   "source": [
    "pipeline_best = grid_search.best_estimator_\n",
    "accuracy = pipeline_best.score(cleaned_test, label_test)\n",
    "print('The accuracy on testing set is: {0:.1f}%'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最优参数组合能使分类器达到80.6% 的准确率"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
