{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 通过梯度下降训练Logistic Regression模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，我们的问题是如何解得最佳w，其能最小化Log loss：![cost_function](cost_function_T.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过梯度下降求解。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent 又称steepest descent：通过一阶迭代优化的方式，最小化目标函数，的过程。\n",
    "    \n",
    "    w := w - ƞ∇w\n",
    "![iteration](gradient_descent.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "w经过足够的迭代更新后，学得的w,b可用于分类新样本x':\n",
    "![for_new_sample](classification.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "默认决策阈值是0.5，也可以是其他值。\n",
    "\n",
    "**假阴**务必避免的情况：预警，预测火灾发生（positive)，阈值可以<0.5，如0.3\n",
    "\n",
    "**假阳**务必避免的情况：品控，预测产品良品率，阈值可以>0.5，如0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 从零实现Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(input):\n",
    "    return 1.0/(1 + np.exp(-input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基于当前的w计算y_hat："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_prediction(X, weights):\n",
    "    \"\"\"Compute the prediction y_hat based on current weights\n",
    "    Args:\n",
    "        X (numpy.ndarray)\n",
    "        weights (numpy.ndarray)\n",
    "    Return:\n",
    "        numpy.ndarray, y_hat of X under weights\n",
    "    \"\"\"\n",
    "    z = np.dot(X, weights)\n",
    "    predictions = sigmoid(z)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### w的更新函数：\n",
    "![](gradient_descent.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_weights_gd(X_train, y_train, weights, learning_rate):\n",
    "    \"\"\"Update weights by one step\n",
    "    Arg：\n",
    "        X_train, y_train (np.ndarray, training data set)\n",
    "        weights (np.ndarray)\n",
    "        learning_rate (float)\n",
    "    Return:\n",
    "        numpy.ndarray, updated weights\n",
    "    \"\"\"\n",
    "    predictions = compute_prediction(X_train, weights)\n",
    "    weights_delta = np.dot(X_train.T, y_train-predictions)\n",
    "    m = y_train.shape[0]\n",
    "    weights += learning_rate / float(m) *weights_delta\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算代价函数：\n",
    "![cost_function](cost_function_T.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_cost(X, y, weights):\n",
    "    \"\"\"Compute the cost J(w)\n",
    "    Args:\n",
    "        X, y (numpy.ndarray, data set)\n",
    "        weights (numpy.ndarray)\n",
    "    Returns:\n",
    "        float\n",
    "    \"\"\"\n",
    "    predictions = compute_prediction(X, weights)\n",
    "    cost = np.mean(-y * np.log(predictions) - (1-y)*np.log(1-predictions))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 联合以上得到模型训练函数：\n",
    "    每次迭代更新w；\n",
    "    每1000次迭代，print当前cost，确保cost确实在下降"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_logistic_regression(X_train, y_train, max_iter, learning_rate, fit_intercept=False):\n",
    "    \"\"\"Train a logistic regression model\n",
    "    Args:\n",
    "        X_train, y_train (numpy.nparray, training data set)\n",
    "        max_iter (int, number of iterations)\n",
    "        learning_rate (float)\n",
    "        fit_intercept (bool, with an intercept w0 or not)\n",
    "    Return:\n",
    "        numpy.ndarray, learned weights\n",
    "    \"\"\"\n",
    "    if fit_intercept: # 如果有w0，加一列\n",
    "        intercept = np.ones((X_train.shape[0], 1)) \n",
    "        X_train = np.hstack((intercept, X_train))\n",
    "    weights = np.zeros(X_train.shape[1])\n",
    "    for iteration in range(max_iter):\n",
    "        weights = update_weights_gd(X_train,y_train,weights,learning_rate)\n",
    "        if iteration % 1000 == 0:\n",
    "            print(compute_cost(X_train,y_train,weights))\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 最好，用训练好的模型预测新样本："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(X, weights):\n",
    "    if X.shape[1] == weights.shape[0] - 1: # 新样本的特征数应与w数一致\n",
    "        intercept = np.ones((X.shape[0],1))\n",
    "        X = np.hstack((intercept, X))\n",
    "    return compute_prediction(X, weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.array([[6, 7],\n",
    "                    [2, 4],\n",
    "                    [3, 6],\n",
    "                    [4, 7],\n",
    "                    [1, 6],\n",
    "                    [5, 2],\n",
    "                    [2, 0],\n",
    "                    [6, 3],\n",
    "                    [4, 1],\n",
    "                    [7, 2]])\n",
    "\n",
    "y_train = np.array([0,\n",
    "                    0,\n",
    "                    0,\n",
    "                    0,\n",
    "                    0,\n",
    "                    1,\n",
    "                    1,\n",
    "                    1,\n",
    "                    1,\n",
    "                    1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.574404237166\n",
      "0.0344602233925\n",
      "0.0182655727085\n",
      "0.012493458388\n",
      "0.00951532913855\n",
      "0.00769338806065\n",
      "0.00646209433351\n",
      "0.00557351184683\n",
      "0.00490163225453\n",
      "0.00437556774067\n"
     ]
    }
   ],
   "source": [
    "weights = train_logistic_regression(X_train, y_train, max_iter=1000,\n",
    "                                    learning_rate=0.1,fit_intercept=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = np.array([[6, 1],\n",
    "                   [1, 3],\n",
    "                   [3, 1],\n",
    "                   [4, 5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = predict(X_test, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.9999478 ,  0.00743991,  0.9808652 ,  0.02080847])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x11124b9b0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAE5BJREFUeJzt3X1sXfV9x/H3105sx8nKU0zIeArrCg0qlBQrgAIMqDIe\nVljWIfqg0WoSSoVogbUFOqSqqro/JrUik7oylQJru7W0Gx2UkTJgDBZoyoNDUlogqF2BlmgBs0BC\nnMQ2yXd/3FtKSIiv7Xt98rt5v6Sr+P7u8T2fg9HH5/7u7/pEZiJJKkdH1QEkSeNjcUtSYSxuSSqM\nxS1JhbG4JakwFrckFcbilqTCWNySVBiLW5IKM60VTzp79uycN29eK55aktrSqlWrXs7Mvka2bUlx\nz5s3j4GBgVY8tSS1pYh4vtFtnSqRpMJY3JJUGItbkgpjcUtSYSxuSSrMmMUdEcdExJo33TZFxJVT\nEU5qhs2b4dpr4cgj4aij4ItfhK1bq061b3v9dVi2DI4+Gg47DD71KXj55apTlSPGcwWciOgE1gEn\nZebbLl3p7+9PlwNqb7B9O/T3w9NPw/BwbWzGDHjf++DBByGi2nz7qosuguXLYcuW2v2uLpg7F558\nEmbOrDZbVSJiVWb2N7LteKdK3g/8z55KW9qbLF8Ov/zl70obamfbP/0pPPBAZbH2aWvXwp13/q60\nAUZGamfc3/52dblKMt7i/jBwSyuCSK3w6KO1qZK32rYNfFFYjYEB6OzcdXxoCFasmPo8JWq4uCOi\nC7gA+Ne3eXxpRAxExMDg4GCz8kmTcuSRu3/pPWMGHH741OcRHHHE7se7uuAP/3Bqs5RqPGfc5wKP\nZ+aLu3swM2/IzP7M7O/ra+jj9lLLfehDtUJ481x2RK24lyypLte+7LTT4NBDYdpb/uBGVxd84hPV\nZCrNeIr7IzhNosK84x21l9/HHQfd3bVyOPFEeOgh6OmpOt2+KQLuv79W4F1dtZ/DO98Jd99dW2Gi\nsTW0qiQiZgK/Bv4gMzeOtb2rSrQ3evFF6OgAXxDuPTZsqL3fMHeuK3zGs6qkob8OmJlDwEGTSiVV\nbM6cqhPorQ48sOoEZfKTk5JUGItbkgpjcUtSYSxuSSqMxS1JhbG4JakwFrckFcbilqTCWNySVBiL\nW5IKY3FLUmEsbkkqjMUtSYWxuCWpMBa3JBXG4pakwljcklQYi1uSCmNxS1JhGiruiNg/Im6NiLUR\n8XREnNLsIA88AEuWwCmnwN/8Dbz6arP3oPF64gm4+GI46ST49Kdh3bqqE0mCxq/y/i3gwcy8MSK6\ngN7MfNtqHe9V3q+/Hq66CrZsqd3v6YFDDoHVq2H//Rt+GjXRPffAn/1Z7QrcO3ZAVxf09sLAALzz\nnVWnk9rPeK7yPuYZd0TsB5wO3ASQmSN7Ku3xGhraubShVhbr18Pf/32z9qLxyISlS2s/kx07amMj\nI7BpE1x7bbXZJDU2VXIUMAj8Y0SsjogbI2JmswKsXg3Tpu06vm0b/Pu/N2svGo+XX6794nyrHTvg\nvvumPo+knTVS3NOA9wH/kJkLgCHgc2/dKCKWRsRARAwMDg42HOCgg+D113f/2CGHNPw0aqKZe/i1\nfMABU5dD0u41UtwvAC9k5iP1+7dSK/KdZOYNmdmfmf19fX0NB5g/H445Bjo7dx7v7YUrr2z4adRE\nvb3w538O3d27jv/VX1WTSdLvjFncmbke+E1EHFMfej/wVDND3HknvOc9tWLYbz+YMQP+9m/hzDOb\nuReNx9e/Xvvv39NT+5l0d8Mll8Cll1adTNJuZpd361PAd+orSn4F/GUzQ/z+78OaNfDUU/B//wcL\nFsCsWc3cg8Zr1iy46y547jn49a/h2GNh9uyqU0mCBos7M9cADS1TmYxjj231HjRe8+bVbpL2Hn5y\nUpIKY3FLUmEsbkkqjMUtSYWxuCWpMBa3JBXG4pakwljcklQYi1uSCmNxS1JhLG5JKozFLUmFsbgl\nqTAWtyQVxuKWpMJY3JJUGItbkgpjcUtSYSxuSSpMQ9ecjIjngNeA7cDrmdny609Kknav0au8A5yZ\nmS+3LIkkqSFOlUhSYRot7gT+MyJWRcTSVgaSJO1Zo1Mlp2bmuog4GLg3ItZm5oo3b1Av9KUARxxx\nRJNjSpJ+q6Ez7sxcV//3JeA2YOFutrkhM/szs7+vr6+5KSVJbxizuCNiZkT83m+/Bv4Y+Hmrg0mS\ndq+RqZI5wG0R8dvtv5uZ/9HSVJKktzVmcWfmr4D3TkEWSVIDXA4oSYWxuCWpMBa3JBXG4pakwljc\nklQYi1uSCmNxS1JhLG5JKozFLUmFsbglqTAWtyQVxuKWpMJY3JJUGItbkgpjcUtSYSxuSSqMxS1J\nhbG4JakwFrckFaaRiwUDEBGdwACwLjM/0LpI5VuzBu65B/bbDy68EA46qOpEktpJw8UNXAE8Dbyj\nRVmKlwlLl8J3vwujozB9OnzmM3DbbbB4cdXpJLWLhqZKIuIw4E+AG1sbp2zLl8Mtt8CWLbXi3rIF\nhoZqZ93Dw1Wnk9QuGp3j/jvgamBHC7MU75vfrBX17vz3f09pFEltbMzijogPAC9l5qoxtlsaEQMR\nMTA4ONi0gCXJnNhjkjQejZxxLwIuiIjngO8BZ0XEP791o8y8ITP7M7O/r6+vyTHLcPHFMHPmruOZ\n8Ed/NPV5JLWnMYs7M/86Mw/LzHnAh4H/ysy/aHmyAl1wASxZUivvjg7o6YHe3tq8d09P1ekktYvx\nrCrRGDo64J/+CR59FO6+u7Yc8EMfgkMOqTqZpHYyruLOzAeAB1qSpE1EwEkn1W6S1Ap+clKSCmNx\nS1JhLG5JKozFLUmFsbglqTAWtyQVxuKWpMJY3JJUGItbkgpjcUtSYSxuSSqMxS1JhbG4JakwFrck\nFcbilqTCWNySVBiLW5IKY3FLUmEsbkkqzJjXnIyIHmAF0F3f/tbM/EKrg0lqbyMjI9x3330MDQ1x\n5plnctBBB1UdqRiNXCx4GDgrMzdHxHTgoYi4KzMfbnE2SW3q4Ycf5rzzzmP79u1kJqOjo3zlK1/h\nsssuqzpaEcacKsmazfW70+u3bGkqSW1reHiYc889l1deeYVNmzbx2muvsW3bNq666ipWr15ddbwi\nNDTHHRGdEbEGeAm4NzMfaW0sSe3qnnvuYceOHbuMj4yMcPPNN1eQqDwNFXdmbs/ME4DDgIUR8Z63\nbhMRSyNiICIGBgcHm51TUpvYvHkzmbu+aN++fTsbN26sIFF5xrWqJDNfBe4HztnNYzdkZn9m9vf1\n9TUrn6Q2c9ZZZzE6OrrL+KxZs/jgBz9YQaLyjFncEdEXEfvXv54BLAbWtjqYpPY0Z84cvvSlL9Hb\n20tHR62CZs6cyamnnsr5559fcboyNLKqZC7wrYjopFb0/5KZd7Y2lqR29tnPfpbTTz+dG2+8kdde\ne40LL7yQJUuW0NnZWXW0IoxZ3Jn5BLBgCrJI2ocsXLiQhQsXVh2jSH5yUpIKY3FLUmEsbkkqjMUt\nSYWxuCWpMBa3JBXG4pakwljcklQYi1uSCmNxS1JhLG5JKozFLUmFsbglqTAWtyQVxuKWpMJY3JJU\nGItbkgpjcUtSYSxuSSqMxS0VZsOGDTzyyCO8+OKLVUdR3dDQEI8++ijPP//8lOxvzOKOiMMj4v6I\neCoinoyIK6YimKSd7dixg8svv5xDDz2Us88+myOPPJKPfvSjDA8PVx1tn7Zs2TIOPvhgFi9ezLvf\n/W7OOOMMNmzY0NJ9NnLG/Trwmcw8FjgZuCwijm1pKkm7WLZsGTfddBPbtm1j48aNDA8Pc/vtt3P1\n1VdXHW2fddddd/H5z3+eLVu2sGnTJrZt28bKlSu56KKLWrrfMYs7M/83Mx+vf/0a8DRwaEtTSdrF\nsmXL2LJly05jW7du5Rvf+Abbt2+vKNW+7ctf/jJDQ0M7jY2OjvLjH/+YdevWtWy/45rjjoh5wALg\nkd08tjQiBiJiYHBwsDnpJL3hlVde2e34yMgIIyMjU5xGAOvXr9/teFdXF63swYaLOyJmAT8ArszM\nTW99PDNvyMz+zOzv6+trZkZJwCmnnLLb8Xe9613MmDFjitMI4Oyzz2b69Om7jGcm8+fPb9l+Gyru\niJhOrbS/k5n/1rI0kt7Wddddx6xZs+js7ASgo6OD3t5err/++oqT7buuueYaDjjgALq6ut4Y6+3t\n5brrrqO7u7tl+21kVUkANwFPZ+Z1LUsiaY+OP/54Vq9ezcc//nGOO+44LrroIlauXMmZZ55ZdbR9\n1iGHHMITTzzB5ZdfzvHHH895553H8uXLueSSS1q638jMPW8QcSrwIPAzYEd9+NrM/NHbfU9/f38O\nDAw0LaQktbuIWJWZ/Y1sO22sDTLzISAmnUqS1BR+clKSCmNxS1JhLG5JKozFLUmFsbglqTAWtyQV\nxuKWpMJY3JJUGItbkgpjcUtSYSxuSSqMxS1JhbG4JakwFrckFcbilqTCWNySVBiLW5IKY3FLUmEs\nbu0zXn31VTZt2lR1DGnSGrnK+80R8VJE/HwqAknN9swzz3DSSSdx8MEHM3v2bE477TSeffbZqmNJ\nE9bIGfc3gXNanENqic2bN7No0SIee+wxRkdHGR0dZeXKlSxatIjh4eGq40kTMmZxZ+YKYMMUZJGa\n7vvf/z7btm0jM98Y27FjB5s3b+aOO+6oMJk0cU2b446IpRExEBEDg4ODzXpaaVKeffZZhoaGdhnf\nunUrzz333NQHkpqgacWdmTdkZn9m9vf19TXraaVJOfHEE5k1a9Yu4z09PSxYsKCCRNLkuapEbe38\n88/niCOOoLu7+42x7u5u5s+fz1lnnVVhMmniLG61tWnTprFy5UouvfRS5syZw9y5c7niiiu4//77\n6ejwf3+VKd78ps1uN4i4BTgDmA28CHwhM2/a0/f09/fnwMBAszJKUtuLiFWZ2d/IttPG2iAzPzL5\nSJKkZvG1oiQVxuKWpMJY3JJUGItbkgpjcUtSYSxuSSqMxS1JhbG4JakwFrckFcbilqTCWNySVBiL\nW5IKY3FLUmEsbkkqjMUtSYWxuCWpMBa3JBXG4pakwljcklSYhoo7Is6JiGci4pcR8blWhyrZM888\nwznnnENPTw8HHngg11xzDcPDw1XHktRGxrxYcER0Al8DFgMvAI9FxB2Z+VSrw5Vm/fr1nHzyyWzc\nuJHMZHh4mK9+9ausXbuWH/7wh1XHk9QmGjnjXgj8MjN/lZkjwPeAP21trDJ97WtfY+vWrWTmG2Nb\nt27l3nvv5Re/+EWFySS1k0aK+1DgN2+6/0J9TG/x2GOP7XZaZPr06Tz1lC9QJDVH096cjIilETEQ\nEQODg4PNetqivPe976Wrq2uX8dHRUY4++ugKEklqR40U9zrg8DfdP6w+tpPMvCEz+zOzv6+vr1n5\nivLJT36S7u7uncZ6enpYtGgR8+fPryiVpHbTSHE/BrwrIo6KiC7gw8AdrY1VpsMPP5wVK1Zw8skn\n09HRQU9PDx/72Me4/fbbq44mqY2MuaokM1+PiE8CdwOdwM2Z+WTLkxXqhBNO4Cc/+Qnbt2+no6OD\niKg6kqQ2M2ZxA2Tmj4AftThLW+ns7Kw6gqQ25ScnJakwFrckFcbilqTCWNySVBiLW5IKE2/+uxpN\ne9KIQeD5CX77bODlJsapUrscS7scB3gse6N2OQ6Y3LEcmZkNfXqxJcU9GRExkJn9VedohnY5lnY5\nDvBY9kbtchwwdcfiVIkkFcbilqTC7I3FfUPVAZqoXY6lXY4DPJa9UbscB0zRsex1c9ySpD3bG8+4\nJUl7sNcUd0TcHBEvRcTPq84yGRFxeETcHxFPRcSTEXFF1ZkmKiJ6IuLRiPhp/Vi+WHWmyYiIzohY\nHRF3Vp1lMiLiuYj4WUSsiYiBqvNMRkTsHxG3RsTaiHg6Ik6pOtN4RcQx9Z/Fb2+bIuLKlu5zb5kq\niYjTgc3AtzPzPVXnmaiImAvMzczHI+L3gFXAkhIvrhy1v0k7MzM3R8R04CHgisx8uOJoExIRnwb6\ngXdk5geqzjNREfEc0J+Zxa99johvAQ9m5o31v/ffm5mvVp1rouoXV18HnJSZE/0sy5j2mjPuzFwB\nbKg6x2Rl5v9m5uP1r18DnqbQa3Rmzeb63en1297xm36cIuIw4E+AG6vOopqI2A84HbgJIDNHSi7t\nuvcD/9PK0oa9qLjbUUTMAxYAj1SbZOLq0wtrgJeAezOz1GP5O+BqYEfVQZoggf+MiFURsbTqMJNw\nFDAI/GN9CuvGiJhZdahJ+jBwS6t3YnG3SETMAn4AXJmZm6rOM1GZuT0zT6B2rdGFEVHcNFZEfAB4\nKTNXVZ2lSU6t/0zOBS6rTzOWaBrwPuAfMnMBMAR8rtpIE1ef6rkA+NdW78viboH6fPAPgO9k5r9V\nnacZ6i9h7wfOqTrLBCwCLqjPDX8POCsi/rnaSBOXmevq/74E3AYsrDbRhL0AvPCmV3G3UivyUp0L\nPJ6ZL7Z6RxZ3k9Xf0LsJeDozr6s6z2RERF9E7F//egawGFhbbarxy8y/zszDMnMetZey/5WZf1Fx\nrAmJiJn1N72pTyv8MVDkSqzMXA/8JiKOqQ+9HyjuTfw3+QhTME0CDV5zcipExC3AGcDsiHgB+EJm\n3lRtqglZBFwM/Kw+Nwxwbf26naWZC3yr/k55B/AvmVn0Uro2MAe4rX4R6mnAdzPzP6qNNCmfAr5T\nn2b4FfCXFeeZkPov0cXAJ6Zkf3vLckBJUmOcKpGkwljcklQYi1uSCmNxS1JhLG5JKozFLUmFsbgl\nqTAWtyQV5v8BhlhUqXBsWtIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111098898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X_train[:,0], X_train[:, 1], c=['b']*5+['k']*5, marker='o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 若阈值为0.5："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEKCAYAAAARnO4WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111761358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X_train[:,0], X_train[:, 1], c=['b']*5+['k']*5, marker='o')\n",
    "colors = ['k' if prediction >= 0.5 else 'b' for prediction in predictions]\n",
    "plt.scatter(X_test[:,0], X_test[:,1],marker='+', c = colors)\n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('x2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 梯度下降训练LR模型 及CTR预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def read_ad_click_data(n, offset=0):\n",
    "    X_dict, y = [], []\n",
    "    with open('../../../Test/CTR/train.csv', 'r') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for i in range(offset):\n",
    "            next(reader)\n",
    "        i = 0\n",
    "        for row in reader:\n",
    "            i += 1\n",
    "            y.append(int(row['click']))\n",
    "            del row['click'], row['id'], row['hour'], row['device_id'],row['device_ip']\n",
    "            X_dict.append(row)\n",
    "            if i >=n:\n",
    "                break\n",
    "    return X_dict, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = 10000\n",
    "X_dict_train, y_train=read_ad_click_data(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "dict_one_hot_encoder = DictVectorizer(sparse=False)\n",
    "X_train = dict_one_hot_encoder.fit_transform(X_dict_train)\n",
    "\n",
    "X_dict_test,y_test = read_ad_click_data(n,n)\n",
    "X_test = dict_one_hot_encoder.transform(X_dict_test)\n",
    "\n",
    "X_train_10k = X_train\n",
    "y_train_10k = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.682001945674\n",
      "0.43170915857\n",
      "0.425685277505\n",
      "0.422843135343\n",
      "0.420960348782\n",
      "0.419499856125\n",
      "0.418277700999\n",
      "0.417213474173\n",
      "0.416265039542\n",
      "0.415407033145\n",
      "--- 261.713s seconds ---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time = timeit.default_timer()\n",
    "weights = train_logistic_regression(X_train_10k, y_train_10k,max_iter=10000,learning_rate=0.01, fit_intercept=True)\n",
    "print('--- %0.3fs seconds ---' % (timeit.default_timer() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_10k = X_test\n",
    "predictions = predict(X_test_10k, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ROC AUC on testing set is: 0.711\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "print('The ROC AUC on testing set is: {0:.3f}'.format(roc_auc_score(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结果比得上之前用随机森林的。\n",
    "\n",
    "若数据量从10k变为100k，那么用梯度下降训练的LR模型耗费的时间会增加10倍，需要1小时以上。对于大规模数据，如百万级的，怎么处理更快？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 以随机梯地下降SGD训练LR模型\n",
    "基于梯度下降的LR模型，w的每轮迭代更新，都要遍历一遍全部训练样本，因此如果样本数非常大，整个训练过程就非常耗时间。\n",
    "\n",
    "幸运的是，一个小调整就能使LR适应大数据。对于每次w的更新，只涉及一个训练样本，而不是整个训练集。模型每步移动，基于**单个训练样本的计算误差**。全部样本用完，一轮迭代就结束。这是梯度下降的进阶版，随机梯度下降SGD。\n",
    "\n",
    "公式上，每轮迭代：![SGD](SGD.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SGD通常几轮迭代就能收敛（常常少于10轮），大数据集的处理上，比GD快很多。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD的实现："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_weights_sgd(X_train, y_train, weights, learning_rate):\n",
    "    \"\"\" One weight update iteration: moving weights by one step based on each individual sample\n",
    "    Args:\n",
    "        X_train, y_train (numpy.ndarray, training data set)\n",
    "        weights (numpy.ndarray)\n",
    "        learning_rate (float)\n",
    "    Returns:\n",
    "        numpy.ndarray, updated weights\n",
    "    \"\"\"\n",
    "    for X_each, y_each in zip(X_train, y_train):\n",
    "        prediction = compute_prediction(X_each, weights)\n",
    "        weights_delta = X_each.T * (y_each - prediction)\n",
    "        weights += learning_rate * weights_delta\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "原train_logistic_regression 更改一行："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_logistic_regression_SGD(X_train, y_train, max_iter, learning_rate, fit_intercept=False):\n",
    "    \"\"\"Train a logistic regression model\n",
    "    Args:\n",
    "        X_train, y_train (numpy.ndarray, training data set)\n",
    "        max_iter (int, number of iterations)\n",
    "        learning_rate (float)\n",
    "        fit_intercept (bool, with an intercept w0 or not)\n",
    "    Return:\n",
    "        numpy.ndarray, learned weights\n",
    "    \"\"\"\n",
    "    if fit_intercept:\n",
    "        intercept = np.ones((X_train.shape[0], 1))\n",
    "        X_train = np.hstack((intercept, X_train))\n",
    "    weights = np.zeros(X_train.shape[1])\n",
    "    for iteration in range(max_iter):\n",
    "        weights = update_weights_sgd(X_train, y_train, weights, learning_rate) # 只是这里换成SGD\n",
    "        if iteration % 2 == 0 : # 每2轮确认下cost\n",
    "            print(compute_cost(X_train, y_train, weights))\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 测试，10k训练样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.414965479133\n",
      "0.406007112829\n",
      "0.401049374518\n",
      "--- 1.872s seconds ---\n",
      "The ROC AUC on testing set is: 0.720\n"
     ]
    }
   ],
   "source": [
    "start_time = timeit.default_timer()\n",
    "weights = train_logistic_regression_SGD(X_train_10k, y_train_10k, max_iter=5, learning_rate=0.01, fit_intercept=True)\n",
    "print(\"--- %0.3fs seconds ---\" % (timeit.default_timer() - start_time))\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "predictions = predict(X_test_10k, weights)\n",
    "print('The ROC AUC on testing set is: {0:.3f}'.format(roc_auc_score(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "完成训练只需1秒，而去表现比前面的模型更好"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 测试100k:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 100000\n",
    "X_dict_train, y_train = read_ad_click_data(n)\n",
    "dict_one_hot_encoder = DictVectorizer(sparse=False)\n",
    "X_train = dict_one_hot_encoder.fit_transform(X_dict_train)\n",
    "\n",
    "X_train_100k = X_train\n",
    "y_train_100k = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.412786485963\n",
      "0.407850459722\n",
      "0.405457331149\n",
      "--- 67.391s seconds---\n"
     ]
    }
   ],
   "source": [
    "start_time = timeit.default_timer()\n",
    "weights = train_logistic_regression_SGD(X_train_100k, y_train_100k, max_iter=5,\n",
    "                                    learning_rate=0.01,fit_intercept=True)\n",
    "print('--- %0.3fs seconds---' % (timeit.default_timer() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试，下一个10k样本作测试集："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ROC AUC on testing set is: 0.736\n"
     ]
    }
   ],
   "source": [
    "X_dict_test,y_test_next10k = read_ad_click_data(10000,100000)\n",
    "X_test_next10k = dict_one_hot_encoder.transform(X_dict_test)\n",
    "predictions = predict(X_test_next10k,weights)\n",
    "print('The ROC AUC on testing set is: {0:.3f}'.format(roc_auc_score(y_test_next10k,\n",
    "                                                                    predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_lr = SGDClassifier(loss='log',penalty=None,\n",
    "                       fit_intercept=True,\n",
    "                       n_iter=5,\n",
    "                       learning_rate='constant', # 学习率在进程中不变，默认为‘optimal',即会逐渐减小\n",
    "                       eta0=0.01)  # 学习率为0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ROC AUC on testing set is: 0.737\n"
     ]
    }
   ],
   "source": [
    "sgd_lr.fit(X_train_100k,y_train_100k)\n",
    "predictions = sgd_lr.predict_proba(X_test_next10k)[:,1]\n",
    "print(\"The ROC AUC on testing set is: {0:.3f}\".format(roc_auc_score(y_test_next10k,predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
