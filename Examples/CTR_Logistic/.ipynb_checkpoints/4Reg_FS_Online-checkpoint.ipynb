{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 正则化\n",
    "在cost function中加入正则项：![regularization](regularization.png)\n",
    "\n",
    "其中α是常数，q是范式L1或L2:\n",
    "![L1](L1.png)\n",
    "![L2](L2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练LR模型的过程 就是降低w的代价函数的过程。\n",
    "\n",
    "如果训练到了某个点，它的w非常大，整个cost将由这些很大的w决定。这种情况下，学到的模型对未知数据的泛化会很差。\n",
    "\n",
    "这里引入正则项以惩罚较大的w，因为w现在成为最小化cost的一部分。\n",
    "\n",
    "正则项能消除过拟合。\n",
    "\n",
    "α则是平衡log loss 和泛化。如果α太小，则不能消解过大的w，模型可能出现高方差或过拟合；如果α太大，就很难fit 训练集，表现欠拟合。α 的调优非常重要。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 选择L1 还是L2? \n",
    "经验上，取决于是否需要进行特征选择。\n",
    "\n",
    "classification中，feature selection 是一个过程：选择有效特征的子集。目的是用于构造更好的模型。\n",
    "实务中，并不是每个特征都具有有用的信息；一些特征可能冗余或不相关，因此可以舍弃。公式上，w1x1 + w2x2 ...，不重要的特征，其w就可设为0.\n",
    "\n",
    "### 在LR分类器中，只有L1正则化才能实现特征选择：\n",
    "考虑两个权值向量w1 =(1, 0), w2 = (0.5, 0.5)，假设它们能产生相同的log loss，它们的L1、L2正则项是：\n",
    "![regularization_of_w](regularization_of_w.png)\n",
    "\n",
    "L1(w1) = L1(w2)\n",
    "\n",
    "L2(w2) < L2(w1)\n",
    "\n",
    "这表明，对于分量一大一小显然的w，L2比L1 惩罚更多。换句话说，\n",
    "    \n",
    "    对所有权重，不论大小，L2正则化都倾向给出相对小的值，不偏袒显然很大或显然很小的任意权重。\n",
    "    而L1正则化允许一些权重的值显著大或显著小。\n",
    "    \n",
    "只有L1正则化，某些权重可以被压缩到接近或正好为0，这样就可以进行特征选择。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn 中，penalty参数可选 'None', 'l1', 'l2', 'None', 'elasticnet'(mixture of l1 and l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征选择的L1正则化："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def read_ad_click_data(n, offset=0):\n",
    "    X_dict, y = [],[]\n",
    "    with open('train.csv','r') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for i in range(offset):\n",
    "            next(reader)\n",
    "        i = 0\n",
    "        for row in reader:\n",
    "            i += 1\n",
    "            y.append(int(row['click']))\n",
    "            del row['click'], row['id'], row['hour'], row['device_id'], row['device_ip']\n",
    "            X_dict.append(row)\n",
    "            if i >= n:\n",
    "                break\n",
    "    return X_dict, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 10000\n",
    "X_dict_train, y_train = read_ad_click_data(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "dict_one_hot_encoder = DictVectorizer(sparse=True)\n",
    "X_train = dict_one_hot_encoder.fit_transform(X_dict_train)\n",
    "\n",
    "X_dict_test, y_test = read_ad_click_data(n,n)\n",
    "X_test = dict_one_hot_encoder.transform(X_dict_test)\n",
    "\n",
    "X_train_10k = X_train\n",
    "y_train_10k = np.array(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征选择"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD LR 模型初始化及训练："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='constant', loss='log', n_iter=5, n_jobs=1,\n",
       "       penalty='l1', power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "l1_feature_selector = SGDClassifier(loss='log', penalty='l1',\n",
    "                                   alpha=0.0001, fit_intercept=True,\n",
    "                                   n_iter=5, learning_rate='constant',\n",
    "                                   eta0=0.01)\n",
    "l1_feature_selector.fit(X_train_10k, y_train_10k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 选出重要特征：\n",
    "基于训练好的模型，使用***transform*** method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/linzhun/anaconda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train_10k_selected = l1_feature_selector.transform(X_train_10k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 629)\n",
      "(10000, 2820)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_10k_selected.shape) \n",
    "print(X_train_10k.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "产生的数据集只含有最重要的629维特征，也就是说其他维的w可能都为0。因为随机梯度的随机性，每次训练选出的特征数会稍有差异。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 进一步看训练好的模型的weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.1697109  0.         0.        ...,  0.         0.         0.       ]]\n"
     ]
    }
   ],
   "source": [
    "print(l1_feature_selector.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 底部10个权重和对应的10个最不重要的特征:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.60701977 -0.44406823 -0.42496192 -0.40632397 -0.40632397 -0.40010368\n",
      " -0.36818184 -0.32234671 -0.3213957  -0.30947936]\n",
      "[ 559 2172   34 2370 2566 1540  278 2113  579 2116]\n"
     ]
    }
   ],
   "source": [
    "print(np.sort(l1_feature_selector.coef_)[0][:10])\n",
    "print(np.argsort(l1_feature_selector.coef_)[0][:10]) # 索引排序"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 最重的10个权重和对应的10个最重要的特征："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.28891887,  0.29265008,  0.30409379,  0.30864271,  0.30979478,\n",
       "        0.3488831 ,  0.35582366,  0.35835959,  0.37607186,  0.38586131])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([2769,  554,  546, 2275,  547, 2149, 2580, 1503, 1519, 2761])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(l1_feature_selector.coef_)[0][-10:]\n",
    "np.argsort(l1_feature_selector.coef_)[0][-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 我们也能找出具体是哪些特征："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'site_id=d9750ee7'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'C21=13'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_one_hot_encoder.feature_names_[2761]\n",
    "dict_one_hot_encoder.feature_names_[546]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们已能处理100k样本量，比这更大呢？接下来讲如何以online learning 训练大规模数据集。\n",
    "\n",
    "SGD由GD发展而来，每次迭代依序更新单个样本，而不是每次都把全部训练集遍历一遍。\n",
    "\n",
    "通过online learning，我们可以进一步放大SGD。\n",
    "\n",
    "Online learning 中，用于训练的新数据可以实时地或依序地投喂，而不像在离线学习环境中一次性投入。\n",
    "\n",
    "一次训练只需载入、预处理一个相对小的数据块，这样就释放了用于保存整个大型数据集的内存。比如，我可以将4000万分成20个200万，依次投入每个200万。\n",
    "\n",
    "除了更好的计算可行性，online learning 的适用性能满足很多现代化场景需要。比如股价预测模型，广告点击预测模型，垃圾邮件检测，其数据都是实时产生和更新的，基于最新数据训练已有模型即可，而不是基于旧数据和新数据从头再建模。\n",
    "\n",
    "\n",
    "\n",
    "![](online_learning.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实现：\n",
    "    \n",
    "    SGDClassifier.partial_fit (之前用的 .fit 即是离线学习）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练百万级样本量：10 x 100k = 100W样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd_lr = SGDClassifier(loss='log', penalty=None, \n",
    "                      fit_intercept=True,\n",
    "                      n_iter=1,  # 如果使用partial_fit，n_iter设为1\n",
    "                      learning_rate = 'constant',\n",
    "                      eta0=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='constant', loss='log', n_iter=1, n_jobs=1,\n",
       "       penalty=None, power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='constant', loss='log', n_iter=1, n_jobs=1,\n",
       "       penalty=None, power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='constant', loss='log', n_iter=1, n_jobs=1,\n",
       "       penalty=None, power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='constant', loss='log', n_iter=1, n_jobs=1,\n",
       "       penalty=None, power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='constant', loss='log', n_iter=1, n_jobs=1,\n",
       "       penalty=None, power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='constant', loss='log', n_iter=1, n_jobs=1,\n",
       "       penalty=None, power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='constant', loss='log', n_iter=1, n_jobs=1,\n",
       "       penalty=None, power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='constant', loss='log', n_iter=1, n_jobs=1,\n",
       "       penalty=None, power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='constant', loss='log', n_iter=1, n_jobs=1,\n",
       "       penalty=None, power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='constant', loss='log', n_iter=1, n_jobs=1,\n",
       "       penalty=None, power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='constant', loss='log', n_iter=1, n_jobs=1,\n",
       "       penalty=None, power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='constant', loss='log', n_iter=1, n_jobs=1,\n",
       "       penalty=None, power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='constant', loss='log', n_iter=1, n_jobs=1,\n",
       "       penalty=None, power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='constant', loss='log', n_iter=1, n_jobs=1,\n",
       "       penalty=None, power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='constant', loss='log', n_iter=1, n_jobs=1,\n",
       "       penalty=None, power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='constant', loss='log', n_iter=1, n_jobs=1,\n",
       "       penalty=None, power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='constant', loss='log', n_iter=1, n_jobs=1,\n",
       "       penalty=None, power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='constant', loss='log', n_iter=1, n_jobs=1,\n",
       "       penalty=None, power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='constant', loss='log', n_iter=1, n_jobs=1,\n",
       "       penalty=None, power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='constant', loss='log', n_iter=1, n_jobs=1,\n",
       "       penalty=None, power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 440.872s seconds ---\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "for i in range(20):\n",
    "    X_dict_train, y_train_every_100k = read_ad_click_data(100000, i*100000)\n",
    "    X_train_every_100k = dict_one_hot_encoder.transform(X_dict_train)\n",
    "    sgd_lr.partial_fit(X_train_every_100k,y_train_every_100k,classes=[0,1])\n",
    "    \n",
    "print(\"--- %0.3fs seconds ---\" % (timeit.default_timer() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用在线学习，百万级样本的训练也能很快。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_dict_test, y_test_next10k = read_ad_click_data(10000, (i+1)*200000)\n",
    "X_test_next10k = dict_one_hot_encoder.transform(X_dict_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ROC AUC on testing set is: 0.714\n"
     ]
    }
   ],
   "source": [
    "predictions = sgd_lr.predict_proba(X_test_next10k)[:,1]\n",
    "print(\"The ROC AUC on testing set is: {0:.3f}\".format(roc_auc_score(y_test_next10k,predictions)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
