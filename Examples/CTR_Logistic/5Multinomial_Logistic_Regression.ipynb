{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass Classification\n",
    "\n",
    "虽然我们通过sklearn 也能像处理二分类那样用相同的方式对待多分类问题，但值得去理解LR处理多分类问题的原理。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多项Logistic Regression，近来也以softmax regression 闻名。\n",
    "\n",
    "回忆下二分类的情况，模型用1个w 向量 表示，target为positive(1)的概率为：![being_1](probability.png)\n",
    "\n",
    "\n",
    "\n",
    "K-class: 模型用K个w 向量表示， w1,w2,...,wK, target为k的概率为：![being_k](k_class_probability.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意正规化，所有k的概率和为1。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "二分类的代价函数为：![binary_cost_function](cost_function_T.png)\n",
    "\n",
    "k分类的代价函数为：![k_cost_function](k_cost_function.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有了代价函数之后，就能迭代求解最佳w：![weights_delta](k_weights_delta.png)\n",
    "有了最佳w后，就有了预测新样本的模型：![predictor](predictor_with_optimal_w.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 下面以新闻主题分类为例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from nltk.corpus import names\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_names = set(names.words())\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def letters_only(astr):\n",
    "    for c in astr:\n",
    "        if not c.isalpha():\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def clean_text(docs):\n",
    "    cleaned_docs = []\n",
    "    for doc in docs:\n",
    "        cleaned_docs.append(' '.join([lemmatizer.lemmatize(word.lower())\n",
    "                                         for word in doc.split()\n",
    "                                         if letters_only(word)\n",
    "                                         and word not in all_names]))\n",
    "    return cleaned_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_train = fetch_20newsgroups(subset='train', categories=None, random_state=42)\n",
    "data_test = fetch_20newsgroups(subset='test', categories = None, random_state=42)\n",
    "\n",
    "cleaned_train = clean_text(data_train.data)\n",
    "label_train = data_train.target\n",
    "cleaned_test = clean_text(data_test.data)\n",
    "label_test = data_test.target\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5, stop_words='english',\n",
    "                                   max_features=40000)\n",
    "term_docs_train = tfidf_vectorizer.fit_transform(cleaned_train)\n",
    "term_docs_test = tfidf_vectorizer.transform(cleaned_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1e-06, 'eta0': 10, 'penalty': None}\n",
      "The accuracy on testing set is: 79.6%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'penalty': ['l2', None],\n",
    "              'alpha': [1e-07, 1e-06, 1e-05, 1e-04],\n",
    "              'eta0': [0.01, 0.1, 1, 10]}\n",
    "\n",
    "sgd_lr = SGDClassifier(loss='log', learning_rate='constant', eta0=0.01, fit_intercept=True, n_iter=10)\n",
    "\n",
    "grid_search = GridSearchCV(sgd_lr, parameters, n_jobs=-1, cv=3)\n",
    "\n",
    "grid_search.fit(term_docs_train, label_train)\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "sgd_lr_best = grid_search.best_estimator_\n",
    "accuracy = sgd_lr_best.score(term_docs_test, label_test)\n",
    "print('The accuracy on testing set is: {0:.1f}%'.format(accuracy*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
