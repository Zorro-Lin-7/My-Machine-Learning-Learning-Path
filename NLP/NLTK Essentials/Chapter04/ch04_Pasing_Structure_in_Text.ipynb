{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The rule-based approach:\n",
    "通过代码，人工设定语法规则："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Context Free Grammer\n",
    "from nltk import CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "toy_grammer = CFG.fromstring(\n",
    "\"\"\"\n",
    "S -> NP VP\n",
    "VP -> V NP\n",
    "V -> 'eats' | 'drinks'\n",
    "NP -> DET N\n",
    "Det -> 'a' | 'an' | 'the'\n",
    "N -> 'president' | 'Obama' | 'apple' | 'coke'\n",
    "\"\"\")\n",
    "\n",
    "# 一个完整的句子 =                限定词 + 名词（词组） + 动词（词组） + 限定词 + 名词（词组）\n",
    "# S= NP + VP = NP + (V + NP) = (DET  +   N    ) +   (V + (        DET +    N    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[S -> NP VP,\n",
       " VP -> V NP,\n",
       " V -> 'eats',\n",
       " V -> 'drinks',\n",
       " NP -> DET N,\n",
       " Det -> 'a',\n",
       " Det -> 'an',\n",
       " Det -> 'the',\n",
       " N -> 'president',\n",
       " N -> 'Obama',\n",
       " N -> 'apple',\n",
       " N -> 'coke']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_grammer.productions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 以上给定的规则可生成的句子有：\n",
    "* President eats apple\n",
    "* Obama drinks coke\n",
    "\n",
    "但同样的语法也可能生成无意义的句子：\n",
    "* Apple eats coke\n",
    "* President drinks Obama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different types of parsers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit tests for the  CFG class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk import Nonterminal, nonterminals, Production, CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NP'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nt1 = Nonterminal(\"NP\")\n",
    "nt2 = Nonterminal(\"VP\")\n",
    "nt1.symbol()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nt1 == Nonterminal('NP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nt1 == nt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "S, NP, VP, PP = nonterminals('S, NP, VP, PP')\n",
    "N, V, P, DT = nonterminals('N, V, P, DT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'S'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'VP'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S.symbol()\n",
    "VP.symbol()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(DT, NP)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod1 = Production(S, [NP, VP])\n",
    "prod2 = Production(NP, [DT, NP])\n",
    "prod1.lhs() #Return the left-hand side of this ``Production``.\n",
    "prod2.rhs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod1 == Production(S, [NP, VP])\n",
    "prod1 == prod2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grammer = CFG.fromstring(\"\"\"\n",
    "    S -> NP VP\n",
    "    PP -> P NP\n",
    "    NP -> 'the' N | PP | 'the' N PP\n",
    "    VP -> V NP | V PP | V NP PP\n",
    "    N -> 'cat' | 'dog' |'rug'\n",
    "    V -> 'chased'| 'sat'\n",
    "    P -> 'in'|'on'\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[S -> NP VP,\n",
       " PP -> P NP,\n",
       " NP -> 'the' N,\n",
       " NP -> N PP,\n",
       " NP -> 'the' N PP,\n",
       " VP -> V NP,\n",
       " VP -> V PP,\n",
       " VP -> V NP PP,\n",
       " N -> 'cat',\n",
       " N -> 'dog',\n",
       " N -> 'rug',\n",
       " V -> 'chased',\n",
       " V -> 'sat',\n",
       " P -> 'in',\n",
       " P -> 'on']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammar.productions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive Descent Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.parse import RecursiveDescentParser\n",
    "rd = RecursiveDescentParser(grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 分别解析歧义句和非歧义句\n",
    "sentence1 = 'the cat chased the dog'\n",
    "sentence2 = 'the cat chased the dog on the rug'\n",
    "tokens1 = sentence1.split()\n",
    "tokens2 = sentence2.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP the (N cat)) (VP (V chased) (NP the (N dog))))\n"
     ]
    }
   ],
   "source": [
    "for t in rd.parse(tokens1):\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP the (N cat))\n",
      "  (VP (V chased) (NP the (N dog) (PP (P on) (NP the (N rug))))))\n",
      "(S\n",
      "  (NP the (N cat))\n",
      "  (VP (V chased) (NP the (N dog)) (PP (P on) (NP the (N rug)))))\n"
     ]
    }
   ],
   "source": [
    "for t in rd.parse(tokens2):\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sr (Shift Reduce Parser) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.parse import ShiftReduceParser\n",
    "sr = ShiftReduceParser(grammer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP the (N cat)) (VP (V chased) (NP the (N dog))))\n"
     ]
    }
   ],
   "source": [
    "for t in sr.parse(tokens1):\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for t in sr.parse(tokens2):\n",
    "    print(t)     # 只会返回唯一的之前的解析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**当有多个可能的shift or reduce 操作可供选择时，sr 解析器采用heuristics 来做决策。而对于给定的语法，会选择错误的操作。**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chart Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Sentence:\n",
      "I saw a dog\n",
      "['I', 'saw', 'a', 'dog']\n",
      "\n",
      "* Strategy: Bottom-up\n",
      "\n",
      "|.    I    .   saw   .    a    .   dog   .|\n",
      "|[---------]         .         .         .| [0:1] 'I'\n",
      "|.         [---------]         .         .| [1:2] 'saw'\n",
      "|.         .         [---------]         .| [2:3] 'a'\n",
      "|.         .         .         [---------]| [3:4] 'dog'\n",
      "|>         .         .         .         .| [0:0] NP -> * 'I'\n",
      "|[---------]         .         .         .| [0:1] NP -> 'I' *\n",
      "|>         .         .         .         .| [0:0] S  -> * NP VP\n",
      "|>         .         .         .         .| [0:0] NP -> * NP PP\n",
      "|[--------->         .         .         .| [0:1] S  -> NP * VP\n",
      "|[--------->         .         .         .| [0:1] NP -> NP * PP\n",
      "|.         >         .         .         .| [1:1] Verb -> * 'saw'\n",
      "|.         [---------]         .         .| [1:2] Verb -> 'saw' *\n",
      "|.         >         .         .         .| [1:1] VP -> * Verb NP\n",
      "|.         >         .         .         .| [1:1] VP -> * Verb\n",
      "|.         [--------->         .         .| [1:2] VP -> Verb * NP\n",
      "|.         [---------]         .         .| [1:2] VP -> Verb *\n",
      "|.         >         .         .         .| [1:1] VP -> * VP PP\n",
      "|[-------------------]         .         .| [0:2] S  -> NP VP *\n",
      "|.         [--------->         .         .| [1:2] VP -> VP * PP\n",
      "|.         .         >         .         .| [2:2] Det -> * 'a'\n",
      "|.         .         [---------]         .| [2:3] Det -> 'a' *\n",
      "|.         .         >         .         .| [2:2] NP -> * Det Noun\n",
      "|.         .         [--------->         .| [2:3] NP -> Det * Noun\n",
      "|.         .         .         >         .| [3:3] Noun -> * 'dog'\n",
      "|.         .         .         [---------]| [3:4] Noun -> 'dog' *\n",
      "|.         .         [-------------------]| [2:4] NP -> Det Noun *\n",
      "|.         .         >         .         .| [2:2] S  -> * NP VP\n",
      "|.         .         >         .         .| [2:2] NP -> * NP PP\n",
      "|.         [-----------------------------]| [1:4] VP -> Verb NP *\n",
      "|.         .         [------------------->| [2:4] S  -> NP * VP\n",
      "|.         .         [------------------->| [2:4] NP -> NP * PP\n",
      "|[=======================================]| [0:4] S  -> NP VP *\n",
      "|.         [----------------------------->| [1:4] VP -> VP * PP\n",
      "Nr edges in chart: 33\n",
      "(S (NP I) (VP (Verb saw) (NP (Det a) (Noun dog))))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# First, we test tracing with a short sentence\n",
    "nltk.parse.chart.demo(2, print_times=False, trace=1,sent='I saw a dog', numparses=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Sentence:\n",
      "I saw John with a dog\n",
      "['I', 'saw', 'John', 'with', 'a', 'dog']\n",
      "\n",
      "* Strategy: Top-down\n",
      "\n",
      "Nr edges in chart: 48\n",
      "(S\n",
      "  (NP I)\n",
      "  (VP (Verb saw) (NP (NP John) (PP with (NP (Det a) (Noun dog))))))\n",
      "(S\n",
      "  (NP I)\n",
      "  (VP (VP (Verb saw) (NP John)) (PP with (NP (Det a) (Noun dog)))))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# then we test the different parsing Strategies. Note that the number of edges differ between the strategies.\n",
    "# Top - Down\n",
    "nltk.parse.chart.demo(1,print_times=False, trace=0, sent='I saw John with a dog',numparses=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Sentence:\n",
      "I saw John with a dog\n",
      "['I', 'saw', 'John', 'with', 'a', 'dog']\n",
      "\n",
      "* Strategy: Bottom-up\n",
      "\n",
      "Nr edges in chart: 53\n",
      "(S\n",
      "  (NP I)\n",
      "  (VP (VP (Verb saw) (NP John)) (PP with (NP (Det a) (Noun dog)))))\n",
      "(S\n",
      "  (NP I)\n",
      "  (VP (Verb saw) (NP (NP John) (PP with (NP (Det a) (Noun dog))))))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Bottom - up\n",
    "nltk.parse.chart.demo(2,print_times=False, trace=0, sent='I saw John with a dog', numparses=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
