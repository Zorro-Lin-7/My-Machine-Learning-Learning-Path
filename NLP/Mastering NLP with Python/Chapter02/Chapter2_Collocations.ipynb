{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 词频\n",
    "Collocations 词组搭配\n",
    "\n",
    "从text中生成ngrams有2种方法：\n",
    " \n",
    "    使用 collocation finders：nltk.collocation.\n",
    "    使用 ngrams： nltk.util.ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用nltk.util.ngram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139820\n",
      "['De', 'verzekeringsmaatschappijen', 'verhelen', 'niet', 'dat', 'ook', 'de', 'rentegrondslag', 'van', 'vier']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import alpino\n",
    "print(len(alpino.words()))\n",
    "print(alpino.words()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('De',)\n",
      "('verzekeringsmaatschappijen',)\n",
      "('verhelen',)\n",
      "('niet',)\n",
      "('dat',)\n",
      "('ook',)\n",
      "('de',)\n",
      "('rentegrondslag',)\n",
      "('van',)\n",
      "('vier',)\n"
     ]
    }
   ],
   "source": [
    "unigrams = ngrams(alpino.words(), 1)  # 是一个生成器\n",
    "\n",
    "# print 前10个tokens\n",
    "i = 0\n",
    "for token in unigrams:\n",
    "    print(token)\n",
    "    if i == 9:\n",
    "        break\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('De', 'verzekeringsmaatschappijen')\n",
      "('verzekeringsmaatschappijen', 'verhelen')\n",
      "('verhelen', 'niet')\n",
      "('niet', 'dat')\n",
      "('dat', 'ook')\n",
      "('ook', 'de')\n",
      "('de', 'rentegrondslag')\n",
      "('rentegrondslag', 'van')\n",
      "('van', 'vier')\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import alpino\n",
    "bigrams_tokens = ngrams(alpino.words(), 2)\n",
    "\n",
    "i = 0\n",
    "for token in bigrams_tokens:\n",
    "    if i == 9:\n",
    "        break\n",
    "    i += 1\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fourgram or quadgrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('De', 'verzekeringsmaatschappijen', 'verhelen', 'niet')\n",
      "('verzekeringsmaatschappijen', 'verhelen', 'niet', 'dat')\n",
      "('verhelen', 'niet', 'dat', 'ook')\n",
      "('niet', 'dat', 'ook', 'de')\n",
      "('dat', 'ook', 'de', 'rentegrondslag')\n",
      "('ook', 'de', 'rentegrondslag', 'van')\n",
      "('de', 'rentegrondslag', 'van', 'vier')\n",
      "('rentegrondslag', 'van', 'vier', 'procent')\n",
      "('van', 'vier', 'procent', 'nog')\n",
      "('vier', 'procent', 'nog', 'een')\n"
     ]
    }
   ],
   "source": [
    "quadgrams = ngrams(alpino.words(), 4)\n",
    "\n",
    "i = 0\n",
    "for word in quadgrams:\n",
    "    print(word)\n",
    "    if i == 9:\n",
    "        break\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fivegrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Hello', ',', 'please', 'read', 'the')\n",
      "(',', 'please', 'read', 'the', 'book')\n",
      "('please', 'read', 'the', 'book', 'thoroughly')\n",
      "('read', 'the', 'book', 'thoroughly', '.')\n",
      "('the', 'book', 'thoroughly', '.', 'If')\n",
      "('book', 'thoroughly', '.', 'If', 'you')\n",
      "('thoroughly', '.', 'If', 'you', 'have')\n",
      "('.', 'If', 'you', 'have', 'an')\n",
      "('If', 'you', 'have', 'an', 'queries,')\n",
      "('you', 'have', 'an', 'queries,', 'then')\n",
      "('have', 'an', 'queries,', 'then', \"don't\")\n",
      "('an', 'queries,', 'then', \"don't\", 'hesitate')\n",
      "('queries,', 'then', \"don't\", 'hesitate', 'to')\n",
      "('then', \"don't\", 'hesitate', 'to', 'ask')\n",
      "(\"don't\", 'hesitate', 'to', 'ask', '.There')\n",
      "('hesitate', 'to', 'ask', '.There', 'is')\n",
      "('to', 'ask', '.There', 'is', 'no')\n",
      "('ask', '.There', 'is', 'no', 'shortcut')\n",
      "('.There', 'is', 'no', 'shortcut', 'to')\n",
      "('is', 'no', 'shortcut', 'to', 'success')\n",
      "('no', 'shortcut', 'to', 'success', '.')\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "sent = \" Hello , please read the book thoroughly . If you have an queries, then don't hesitate to ask .\\\n",
    "There is no shortcut to success .\"\n",
    "n = 5\n",
    "fivegrams = ngrams(sent.split(), n)\n",
    "for grams in fivegrams:\n",
    "    print(grams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用colloctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scene', '1', ':', '[', 'wind', ']', '[', 'clop', 'clop', 'clop']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[(\"'\", 's'),\n",
       " ('arthur', ':'),\n",
       " ('#', '1'),\n",
       " (\"'\", 't'),\n",
       " ('villager', '#'),\n",
       " ('#', '2'),\n",
       " (']', '['),\n",
       " ('1', ':'),\n",
       " ('oh', ','),\n",
       " ('black', 'knight')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.collocations import BigramCollocationFinder \n",
    "from nltk.corpus import webtext\n",
    "from nltk.metrics import BigramAssocMeasures #??\n",
    "tokens = [t.lower() for t in webtext.words('grail.txt')] # 先小写化 所有词，得到列表\n",
    "tokens[:10]\n",
    "words = BigramCollocationFinder.from_words(tokens)\n",
    "words.nbest(BigramAssocMeasures.likelihood_ratio, 10) # ??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 在上面基础上，消除停用词和标点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('black', 'knight'), ('clop', 'clop'), ('head', 'knight'), ('mumble', 'mumble'), ('squeak', 'squeak'), ('saw', 'saw'), ('holy', 'grail'), ('run', 'away'), ('french', 'guard'), ('cartoon', 'character')]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import webtext\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.metrics import BigramAssocMeasures\n",
    "\n",
    "stopwords_set = set(stopwords.words('english'))\n",
    "stops_filter = lambda w: len(w) < 3 or w in stopwords_set\n",
    "tokens = [t.lower() for t in webtext.words('grail.txt')]\n",
    "words = BigramCollocationFinder.from_words(tokens)\n",
    "words.apply_word_filter(stops_filter)  #??\n",
    "print(words.nbest(BigramAssocMeasures.likelihood_ratio, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hardwork',\n",
       " 'is',\n",
       " 'the',\n",
       " 'key',\n",
       " 'to',\n",
       " 'success',\n",
       " '.',\n",
       " 'Never',\n",
       " 'give',\n",
       " 'up',\n",
       " '!']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('.', 'Never'), ('Hardwork', 'is'), ('Never', 'give'), ('give', 'up'), ('is', 'the'), ('key', 'to'), ('success', '.'), ('the', 'key'), ('to', 'success'), ('up', '!')]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.collocations import *\n",
    "text1 = 'Hardwork is the key to success. Never give up!'\n",
    "word = nltk.wordpunct_tokenize(text1)\n",
    "word\n",
    "finder = BigramCollocationFinder.from_words(word)\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "value = finder.score_ngrams(bigram_measures.raw_freq)   #??\n",
    "print(sorted(bigram for bigram, score in value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quadgram，同时生成词频"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Hello', 'how', 'are', 'you') 1\n",
      "('how', 'are', 'you', 'doing') 1\n",
      "('are', 'you', 'doing', '?') 1\n",
      "('you', 'doing', '?', 'I') 1\n",
      "('doing', '?', 'I', 'hope') 1\n",
      "('?', 'I', 'hope', 'you') 1\n",
      "('I', 'hope', 'you', 'find') 1\n",
      "('hope', 'you', 'find', 'the') 1\n",
      "('you', 'find', 'the', 'book') 1\n",
      "('find', 'the', 'book', 'interesting') 1\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.collocations import *\n",
    "text = 'Hello how are you doing ? I hope you find the book interesting'\n",
    "tokens = nltk.wordpunct_tokenize(text)\n",
    "fourgrams = nltk.collocations.QuadgramCollocationFinder.from_words(tokens)\n",
    "for fourgram, freq in fourgrams.ngram_fd.items():\n",
    "    print(fourgram, freq)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
